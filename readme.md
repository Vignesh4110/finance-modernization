# ğŸ’° Finance Modernization Platform

[![CI Pipeline](https://github.com/Vignesh4110/finance-modernization/actions/workflows/ci.yml/badge.svg)](https://github.com/Vignesh4110/finance-modernization/actions/workflows/ci.yml)
[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/)
[![dbt](https://img.shields.io/badge/dbt-1.7-orange.svg)](https://www.getdbt.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.31-red.svg)](https://streamlit.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **Transforming Legacy AS400 Financial Systems into Modern Cloud-Native Architecture**

A complete end-to-end data engineering project demonstrating the modernization of a legacy IBM AS400/DB2 Accounts Receivable system into a modern data platform with ML and LLM capabilities.

## ğŸ¯ Project Overview

This project simulates modernizing a legacy AS400-based finance system that handles:
- **Accounts Receivable (AR)** processing
- **Invoice Management** 
- **Payment Processing**
- **Collections Workflow**
- **Financial Reporting**

### The Problem (Legacy System)
- RPGLE batch programs running on IBM i
- Fixed-width files with CYYMMDD dates and packed decimals
- Nightly batch jobs via WRKJOBSCDE
- Green screen interfaces (5250)
- No real-time visibility, manual collections process

### The Solution (Modern Platform)
- Python-based data extraction with custom AS400 parser
- dbt for data transformation (Bronze â†’ Silver â†’ Gold)
- Apache Airflow for orchestration
- ML models for payment prediction and risk scoring
- LLM agents (Groq/Llama) for intelligent automation
- Interactive Streamlit dashboard

## ğŸ—ï¸ Architecture
```
AS400 Legacy          Modern Platform
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RPGLE/CL     â”‚     â”‚  Python Extraction                  â”‚
â”‚ DB2/400      â”‚ â”€â”€â–¶ â”‚  dbt Transformations                â”‚
â”‚ WRKJOBSCDE   â”‚     â”‚  Airflow Orchestration              â”‚
â”‚ Query/400    â”‚     â”‚  ML Models + LLM Agents             â”‚
â”‚ Green Screen â”‚     â”‚  Streamlit Dashboard                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

[View Full Architecture Diagram](docs/architecture.md)

## ğŸ› ï¸ Tech Stack

| Layer | Technologies |
|-------|-------------|
| **Data Extraction** | Python, Custom AS400 Parser (CYYMMDD dates, fixed-width files) |
| **Storage** | DuckDB (dev), Snowflake/BigQuery (prod) |
| **Transformation** | dbt Core (Bronze â†’ Silver â†’ Gold medallion architecture) |
| **Orchestration** | Apache Airflow |
| **Machine Learning** | scikit-learn, XGBoost, MLflow |
| **LLM Integration** | Groq (Llama 3.3 70B) - FREE! |
| **Dashboard** | Streamlit, Plotly |
| **CI/CD** | GitHub Actions |
| **Infrastructure** | Docker, Terraform (AWS architecture documented) |

## ğŸ“ Project Structure
```
finance-modernization/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/           # AS400 file parsers
â”‚   â”‚   â”œâ”€â”€ as400_parser.py  # Fixed-width file parser
â”‚   â”‚   â”œâ”€â”€ file_layouts.py  # Copybook definitions
â”‚   â”‚   â””â”€â”€ generate_as400_files.py
â”‚   â”œâ”€â”€ ml/                  # Machine learning models
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ payment_propensity.py
â”‚   â”‚   â”‚   â””â”€â”€ collection_scorer.py
â”‚   â”‚   â””â”€â”€ features/
â”‚   â””â”€â”€ llm_agents/          # LLM-powered agents
â”‚       â””â”€â”€ agents/
â”‚           â”œâ”€â”€ ar_query_agent.py      # Natural language queries
â”‚           â”œâ”€â”€ collections_agent.py   # Email generation
â”‚           â””â”€â”€ legacy_documenter.py   # Code documentation
â”œâ”€â”€ dbt_project/             # dbt transformations
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/         # Bronze â†’ Silver
â”‚   â”‚   â””â”€â”€ marts/           # Silver â†’ Gold
â”‚   â””â”€â”€ seeds/               # Source data
â”œâ”€â”€ airflow/                 # Airflow DAGs
â”‚   â””â”€â”€ dags/
â”œâ”€â”€ streamlit_app/           # Dashboard application
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ scripts/                 # Utility scripts
â”‚   â”œâ”€â”€ generate_seed_data.py
â”‚   â”œâ”€â”€ run_tests.py
â”‚   â””â”€â”€ rebuild_all.py
â”œâ”€â”€ docs/                    # Documentation
â”‚   â”œâ”€â”€ architecture.md
â”‚   â””â”€â”€ legacy_system/       # AS400 documentation
â”œâ”€â”€ data/                    # Data files
â”‚   â””â”€â”€ mock_as400/          # Simulated AS400 exports
â””â”€â”€ tests/                   # Test files
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Git
- Docker (optional, for Airflow)

### Installation
```bash
# Clone the repository
git clone https://github.com/Vignesh4110/finance-modernization.git
cd finance-modernization

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Generate seed data
python scripts/generate_seed_data.py

# Run dbt models
cd dbt_project
dbt seed
dbt run
cd ..

# Launch dashboard
streamlit run streamlit_app/app.py
```

### Set up Groq API (Free)
1. Go to [console.groq.com](https://console.groq.com)
2. Create free account and get API key
3. Create `.env` file:
```bash
echo "GROQ_API_KEY=your_key_here" > .env
```

## ğŸ“Š Features

### 1. AS400 Data Parser
- Parses fixed-width files (CPYTOIMPF exports)
- Converts CYYMMDD dates to standard format
- Handles packed decimal fields
- Generates copybook documentation

### 2. dbt Data Models
- **Staging (Silver)**: Clean and standardize raw data
- **Marts (Gold)**: Business-ready analytics tables
- **Tests**: Data quality validation
- **Documentation**: Auto-generated data catalog

### 3. ML Pipeline
- **Payment Propensity Model**: Predicts likelihood of payment
- **Collection Priority Scorer**: Ranks accounts for collection
- **Risk Categorization**: Classifies customers by risk level

### 4. LLM Agents
- **AR Query Agent**: Natural language to SQL queries
- **Collections Agent**: Generates personalized dunning emails
- **Legacy Documenter**: Auto-documents RPGLE programs

### 5. Interactive Dashboard
- Real-time AR metrics and KPIs
- Aging analysis with drill-down
- Customer risk visualization
- AI-powered query interface
- Collection worklist with email generation

## ğŸ§ª Testing
```bash
# Run all tests
python scripts/run_tests.py

# Run dbt tests
cd dbt_project
dbt test
```

## ğŸ“ˆ Sample Data

The project includes realistic mock data:
- **500 customers** across 4 segments
- **5,000 invoices** with realistic aging distribution
- **1,200+ payments** with various methods
- **10,000 GL entries** for financial tracking

## ğŸ“ Learning Outcomes

This project demonstrates proficiency in:
- Legacy system analysis and modernization strategies
- Data engineering with Python and SQL
- dbt for analytics engineering
- Apache Airflow for workflow orchestration
- Machine learning for business applications
- LLM integration for intelligent automation
- Full-stack dashboard development
- CI/CD and DevOps practices

## ğŸ‘¤ Author

**Vignesh**
- Data Analytics Engineering @ Northeastern University
- Background in AS400/IBM i, DB2, RPGLE
- [GitHub](https://github.com/Vignesh4110)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Anthropic for Claude AI assistance
- Groq for free LLM API access
- dbt Labs for the amazing transformation framework
- Streamlit for the dashboard framework
